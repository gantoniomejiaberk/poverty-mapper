{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "import warnings\n",
    "import boto3\n",
    "import json\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "    batch_size = 128\n",
    "    num_workers = 4\n",
    "    arch = 'resnet50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_s3json(s3, url):\n",
    "    url_parts = urlparse(url, allow_fragments=False)\n",
    "    response = s3.get_object(Bucket=url_parts.netloc, Key=url_parts.path.strip(\"/\"))\n",
    "    content = response['Body']\n",
    "    json_content = json.loads(content.read())\n",
    "    return json_content\n",
    "\n",
    "s3 = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_csvs(csv_list):\n",
    "    return_file = pd.read_csv(csv_list[0], nrows=0)\n",
    "    for csv_file in csv_list:\n",
    "        temp_df = pd.read_csv(csv_file)\n",
    "        return_file = return_file.append(temp_df, ignore_index=True)\n",
    "    return_file['filename'] = \"sentinel2_composite/transformed_data/\" + return_file['filename']\n",
    "    return return_file.drop_duplicates(subset=['filename'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(2048, 1024),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(1024, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(512, n_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''Forward pass'''\n",
    "        return self.layers(x)\n",
    "\n",
    "def get_model(architecture, freeze_layers, num_classes, url):\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    model = timm.create_model(architecture, pretrained = True)\n",
    "    if freeze_layers == 'yes':\n",
    "        set_parameter_requires_grad(model, True)\n",
    "    model.fc = MLP(num_classes)\n",
    "\n",
    "    #print(\"Model fc layer = \" + str(model.fc))\n",
    "    s3_client = boto3.client('s3')\n",
    "    url_parts = urlparse(url, allow_fragments=False)\n",
    "    s3_client.download_file(url_parts.netloc, url_parts.path.strip(\"/\"), 'saved_weights.pth')   \n",
    "    model.load_state_dict(torch.load('saved_weights.pth'))\n",
    "    model = model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsttransforms():\n",
    "    return A.Compose([\n",
    "        A.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "\n",
    "class BirdDataset(Dataset):\n",
    "    def __init__(self, df, mode, transform=None):\n",
    "        self.data = df\n",
    "        self.img_dir = f'./'\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        src_filename = self.data.iloc[idx]['filename']\n",
    "        fname = self.data.iloc[idx]['filename'] + \".png\"\n",
    "        fname = fname.replace('sentinel2_composite/transformed_data/', '')\n",
    "        img_path = f'{self.img_dir}/data/{fname}'\n",
    "        image = cv2.imread(img_path)\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image = image)['image']\n",
    "        image = image.float() / 255.\n",
    "        label = self.data.iloc[idx]['label']\n",
    "\n",
    "        return image, label, src_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = {\n",
    "    \"spec_location\" : \"s3://w210-poverty-mapper/modeling/model_specs/\",\n",
    "    \"weights_location\" : \"s3://w210-poverty-mapper/modeling/model_artifacts/\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = {\n",
    "    \"Bangladesh\" : \"within_country_bangladesh_5k_50d_2_within_even_resnet50_no_20_0.0001_0.1_10_64_4\",\n",
    "    \"Nepal\" : \"within_country_nepal_5k_50d_2_within_even_resnet50_no_30_0.0001_0.1_10_64_4\",\n",
    "    \"Philippines\" : \"within_country_philippines_5k_50d_2_within_even_resnet50_no_30_0.0001_0.1_10_64_4\",\n",
    "    \"Tajikistan\" : \"within_country_tajikistan_5k_50d_2_within_even_resnet50_no_20_0.0001_0.1_10_64_4\",\n",
    "    \"Timor Leste\" : \"within_country_timor_leste_5k_50d_2_within_even_resnet50_no_20_0.0001_0.1_10_64_4\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on(base_name, model_inputs):\n",
    "    tstdataset = BirdDataset(model_inputs, 'test', tsttransforms())\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    model = get_model(args.arch, \"no\", 2, configuration[\"weights_location\"] + base_name + \".pth\")\n",
    "    loaderargs = {'num_workers' : args.num_workers, 'batch_size':args.batch_size, 'pin_memory': False, 'drop_last': False}\n",
    "    tstloader = DataLoader(tstdataset, shuffle = False, **loaderargs)\n",
    "    tstpreds = []\n",
    "    step = 1\n",
    "    model.eval()\n",
    "    print(\"Starting the predictions for \" + base_name)\n",
    "    for img, label, location in tstloader:\n",
    "        inputs = img.to(device, dtype=torch.float)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "            tstpreds.append(outputs)\n",
    "            if step % 100 == 1:\n",
    "                print(\"step : \",step)\n",
    "                #print(\"label: \", label[0], \" predicted: \", outputs.argmax(1).detach().cpu().numpy()[0], \" File: \", location[0])\n",
    "            step = step + 1\n",
    "    predicted_labels = torch.cat(tstpreds).argmax(1).detach().cpu().numpy()\n",
    "    print(\"Done with predictions for \" + base_name)\n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the predictions for within_country_bangladesh_5k_50d_2_within_even_resnet50_no_20_0.0001_0.1_10_64_4\n",
      "step :  1\n",
      "step :  101\n",
      "step :  201\n",
      "Done with predictions for within_country_bangladesh_5k_50d_2_within_even_resnet50_no_20_0.0001_0.1_10_64_4\n",
      "Starting the predictions for within_country_nepal_5k_50d_2_within_even_resnet50_no_30_0.0001_0.1_10_64_4\n",
      "step :  1\n",
      "step :  101\n",
      "Done with predictions for within_country_nepal_5k_50d_2_within_even_resnet50_no_30_0.0001_0.1_10_64_4\n",
      "Starting the predictions for within_country_philippines_5k_50d_2_within_even_resnet50_no_30_0.0001_0.1_10_64_4\n",
      "step :  1\n",
      "step :  101\n",
      "step :  201\n",
      "step :  301\n",
      "step :  401\n",
      "Done with predictions for within_country_philippines_5k_50d_2_within_even_resnet50_no_30_0.0001_0.1_10_64_4\n",
      "Starting the predictions for within_country_tajikistan_5k_50d_2_within_even_resnet50_no_20_0.0001_0.1_10_64_4\n",
      "step :  1\n",
      "step :  101\n",
      "Done with predictions for within_country_tajikistan_5k_50d_2_within_even_resnet50_no_20_0.0001_0.1_10_64_4\n",
      "Starting the predictions for within_country_timor_leste_5k_50d_2_within_even_resnet50_no_20_0.0001_0.1_10_64_4\n",
      "step :  1\n",
      "Done with predictions for within_country_timor_leste_5k_50d_2_within_even_resnet50_no_20_0.0001_0.1_10_64_4\n"
     ]
    }
   ],
   "source": [
    "density_file_base = pd.read_csv(\"s3://w210-poverty-mapper/modeling/metadata/source_data/meta_data_full_updated_density_new_full_value_LZ.csv\")\n",
    "output = pd.DataFrame()\n",
    "\n",
    "for country in countries:\n",
    "    density_file = density_file_base.copy()\n",
    "    base_name = countries[country]\n",
    "    spec = get_s3json(s3, \"s3://w210-poverty-mapper/modeling/model_specs/\" + base_name + \".json\")\n",
    "    csv_files_with_label = combine_csvs([\n",
    "        spec[\"train\"],\n",
    "        spec[\"val\"],\n",
    "        spec[\"test\"]\n",
    "    ])\n",
    "    density_file = pd.merge(density_file, csv_files_with_label, on='filename', how='outer')\n",
    "    model_inputs = density_file[(density_file['countries'] == \"['\" + country + \"']\") & (density_file['Density'] > 50)][['filename', 'label']]\n",
    "    #print(\"Length of model inputs \", len(model_inputs))\n",
    "    predictions = predict_on(base_name, model_inputs)\n",
    "    #print(\"Length of predictions \", len(predictions))\n",
    "    model_inputs['prediction'] = predictions\n",
    "    output = output.append(model_inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122456"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    22021\n",
       "0     5558\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "density_file = density_file_base.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "density_file = pd.merge(density_file, output, on='filename', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156656"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(density_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>zone</th>\n",
       "      <th>center</th>\n",
       "      <th>lat_lon_bounds</th>\n",
       "      <th>utm_bounds</th>\n",
       "      <th>countries</th>\n",
       "      <th>partial_updated</th>\n",
       "      <th>Density</th>\n",
       "      <th>label</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sentinel2_composite/transformed_data/42S/341-0...</td>\n",
       "      <td>42S</td>\n",
       "      <td>(67.78771480363916, 37.195334792066234)</td>\n",
       "      <td>[(67.77493453609193, 37.205298500604044), (67....</td>\n",
       "      <td>BoundingBox(left=391290.0, bottom=4116110.0, r...</td>\n",
       "      <td>['Tajikistan']</td>\n",
       "      <td>False</td>\n",
       "      <td>307.808161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sentinel2_composite/transformed_data/42S/341-0...</td>\n",
       "      <td>42S</td>\n",
       "      <td>(67.78803746297999, 37.175147632248574)</td>\n",
       "      <td>[(67.77526071406628, 37.18511147083712), (67.7...</td>\n",
       "      <td>BoundingBox(left=391290.0, bottom=4113870.0, r...</td>\n",
       "      <td>['Tajikistan']</td>\n",
       "      <td>False</td>\n",
       "      <td>143.624449</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sentinel2_composite/transformed_data/42S/341-0...</td>\n",
       "      <td>42S</td>\n",
       "      <td>(67.7883598008825, 37.15496040109096)</td>\n",
       "      <td>[(67.77558656709091, 37.16492436967268), (67.7...</td>\n",
       "      <td>BoundingBox(left=391290.0, bottom=4111630.0, r...</td>\n",
       "      <td>['Tajikistan']</td>\n",
       "      <td>False</td>\n",
       "      <td>155.264702</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sentinel2_composite/transformed_data/42S/341-0...</td>\n",
       "      <td>42S</td>\n",
       "      <td>(67.78868181768202, 37.134773098609735)</td>\n",
       "      <td>[(67.77591209550492, 37.14473719712704), (67.7...</td>\n",
       "      <td>BoundingBox(left=391290.0, bottom=4109390.0, r...</td>\n",
       "      <td>['Tajikistan']</td>\n",
       "      <td>False</td>\n",
       "      <td>154.851017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sentinel2_composite/transformed_data/42S/341-0...</td>\n",
       "      <td>42S</td>\n",
       "      <td>(67.7890035137133, 37.1145857248212)</td>\n",
       "      <td>[(67.7762372996468, 37.124549953216665), (67.7...</td>\n",
       "      <td>BoundingBox(left=391290.0, bottom=4107150.0, r...</td>\n",
       "      <td>['Tajikistan']</td>\n",
       "      <td>False</td>\n",
       "      <td>178.775927</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename zone  \\\n",
       "0  sentinel2_composite/transformed_data/42S/341-0...  42S   \n",
       "1  sentinel2_composite/transformed_data/42S/341-0...  42S   \n",
       "2  sentinel2_composite/transformed_data/42S/341-0...  42S   \n",
       "3  sentinel2_composite/transformed_data/42S/341-0...  42S   \n",
       "4  sentinel2_composite/transformed_data/42S/341-0...  42S   \n",
       "\n",
       "                                    center  \\\n",
       "0  (67.78771480363916, 37.195334792066234)   \n",
       "1  (67.78803746297999, 37.175147632248574)   \n",
       "2    (67.7883598008825, 37.15496040109096)   \n",
       "3  (67.78868181768202, 37.134773098609735)   \n",
       "4     (67.7890035137133, 37.1145857248212)   \n",
       "\n",
       "                                      lat_lon_bounds  \\\n",
       "0  [(67.77493453609193, 37.205298500604044), (67....   \n",
       "1  [(67.77526071406628, 37.18511147083712), (67.7...   \n",
       "2  [(67.77558656709091, 37.16492436967268), (67.7...   \n",
       "3  [(67.77591209550492, 37.14473719712704), (67.7...   \n",
       "4  [(67.7762372996468, 37.124549953216665), (67.7...   \n",
       "\n",
       "                                          utm_bounds       countries  \\\n",
       "0  BoundingBox(left=391290.0, bottom=4116110.0, r...  ['Tajikistan']   \n",
       "1  BoundingBox(left=391290.0, bottom=4113870.0, r...  ['Tajikistan']   \n",
       "2  BoundingBox(left=391290.0, bottom=4111630.0, r...  ['Tajikistan']   \n",
       "3  BoundingBox(left=391290.0, bottom=4109390.0, r...  ['Tajikistan']   \n",
       "4  BoundingBox(left=391290.0, bottom=4107150.0, r...  ['Tajikistan']   \n",
       "\n",
       "   partial_updated     Density label  prediction  \n",
       "0            False  307.808161   NaN         1.0  \n",
       "1            False  143.624449   NaN         1.0  \n",
       "2            False  155.264702   NaN         1.0  \n",
       "3            False  154.851017   NaN         1.0  \n",
       "4            False  178.775927   NaN         1.0  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "density_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "density_file.to_csv(\"combined_labeled.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    22021\n",
       "0     5558\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "density_file.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    96361\n",
       "0.0    26095\n",
       "Name: prediction, dtype: int64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "density_file.prediction.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
